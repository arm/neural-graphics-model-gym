# SPDX-FileCopyrightText: <text>Copyright 2025 Arm Limited and/or
# its affiliates <open-source-office@arm.com></text>
# SPDX-License-Identifier: Apache-2.0

import json
import shutil
import tempfile
import unittest
from pathlib import Path
from types import SimpleNamespace
from unittest.mock import DEFAULT, patch

import torch
from torch import nn

from ng_model_gym.core.model.base_ng_model import BaseNGModel
from ng_model_gym.core.model.base_ng_model_wrapper import BaseNGModelWrapper
from ng_model_gym.core.model.model_factory import get_model_key
from ng_model_gym.core.utils.export_utils import (
    DataLoaderMode,
    executorch_vgf_export,
    ExportType,
    TrainEvalMode,
)


def _flatten(container):
    """Flatten nested containers into a list of tensors."""
    if isinstance(container, torch.Tensor):
        return [container]
    if isinstance(container, (list, tuple)):
        out = []
        for it in container:
            out.extend(_flatten(it))
        return out
    if isinstance(container, dict):
        out = []
        for v in container.values():
            out.extend(_flatten(v))
        return out
    if hasattr(container, "_asdict"):  # namedtuple
        return _flatten(container._asdict())
    return []


class MockNSS(BaseNGModel):
    """Mock class for NSS model."""

    def __init__(self):
        super().__init__()
        self.autoencoder = nn.Identity()

    def get_neural_network(self):
        """Mock get_neural_network"""
        return self.autoencoder

    def set_neural_network(self, neural_network):
        """Mock set_neural_network"""
        self.autoencoder = neural_network

    def get_additional_constants(self):
        """Mock method to return additional constants."""
        return {"foo": "bar"}


class MockFeedbackModel(BaseNGModelWrapper):
    """Mock class for Feedback model."""

    def __init__(
        self,
    ):
        super().__init__()
        self.ng_model = MockNSS()

    def get_ng_model(self) -> BaseNGModel:
        return self.ng_model

    def set_ng_model(self, ng_model: BaseNGModel) -> None:
        self.ng_model = ng_model

    def get_model_input_for_tracing(self, x):
        """Mock method to return model input for tracing."""
        return x

    def get_neural_network(self):
        """Mock get_neural_network"""
        return self.ng_model.get_neural_network()

    def set_neural_network(self, neural_network):
        """Mock set_neural_network"""
        self.ng_model = neural_network


# pylint: disable-next=unused-argument
def fake_dl(params, num_workers, prefetch_factor, loader_mode, trace_mode):
    """A mock one‚Äêbatch dataloader factory"""
    # We could record loader_mode/trace_mode here if needed
    yield (torch.zeros(1, 1),)


def make_params(tmp_path):
    """Make mock parameters for testing."""
    p = SimpleNamespace()

    p.dataset = SimpleNamespace(
        num_workers=2,
        prefetch_factor=4,
        path=SimpleNamespace(train="train_data", test="test_data"),
    )

    p.model = SimpleNamespace(name="NSS", version="42")

    p.output = SimpleNamespace(
        export=SimpleNamespace(
            vgf_output_dir=str(tmp_path / "vgf_output"),
            dynamic_shape=True,
            vgf_static_input_shape=None,
        )
    )
    return p


class TestExportUtils(unittest.TestCase):
    """Tests for export_utils module."""

    def setUp(self):
        """Setup common test data and state"""
        self.tmp_path = Path(tempfile.mkdtemp())

    def tearDown(self):
        """Clean up the temporary directory."""
        shutil.rmtree(self.tmp_path)

    # Patch the heavy or external dependencies on every test:
    @patch("ng_model_gym.core.utils.export_utils._update_metadata_file", new=DEFAULT)
    @patch("ng_model_gym.core.utils.export_utils.get_dataloader", side_effect=fake_dl)
    @patch(
        "ng_model_gym.core.utils.export_utils.load_checkpoint",
        new=lambda *a, **k: MockFeedbackModel(),
    )
    @patch("ng_model_gym.core.utils.export_utils._export_module_to_vgf", new=DEFAULT)
    @patch("ng_model_gym.core.utils.export_utils._check_cuda", new=lambda: None)
    @patch(
        "ng_model_gym.core.utils.export_utils.model_tracer",
        new=lambda model, preprocess: torch.zeros(1, 1),
    )
    def test_qat_int8_path(
        self, mock_export_module_to_vgf, mock_get_dataloader, mock_update_metadata_file
    ):
        """Test the QAT INT8 export path."""
        params = make_params(self.tmp_path)
        executorch_vgf_export(
            params=params,
            export_type=ExportType.QAT_INT8,
            model_path=Path("checkpoint.pth"),
        )

        # Train/eval mode set correctly.
        self.assertEqual(params.model_train_eval_mode, TrainEvalMode.QAT_INT8)

        model_key = get_model_key(params.model.name, params.model.version)

        # Metadata file should be updated with constants.
        expected_meta = Path(params.output.export.vgf_output_dir) / (
            f"{model_key}-{ExportType.QAT_INT8.name}-metadata.json"
        )

        mock_update_metadata_file.assert_called_once_with(expected_meta, {"foo": "bar"})

        # Dataloader correct arguments passed.
        _, kwargs = mock_get_dataloader.call_args
        self.assertEqual(kwargs["loader_mode"], DataLoaderMode.TRAIN)
        self.assertFalse(kwargs["trace_mode"])

        # Export module to a VGF file is called with correct parameters.
        mock_export_module_to_vgf.assert_called_once()
        export_args, _ = mock_export_module_to_vgf.call_args
        _, module, trace_input, etype, meta_path = export_args
        self.assertIsInstance(module, BaseNGModel)
        self.assertIsInstance(trace_input, torch.Tensor)
        self.assertEqual(etype, ExportType.QAT_INT8)

        model_key = get_model_key(params.model.name, params.model.version)

        # Metadata path should match the expected path.
        expected_meta = Path(params.output.export.vgf_output_dir) / (
            f"{model_key}-{ExportType.QAT_INT8.name}-metadata.json"
        )

        self.assertEqual(meta_path, expected_meta)

    @patch("ng_model_gym.core.utils.export_utils._update_metadata_file", new=DEFAULT)
    @patch("ng_model_gym.core.utils.export_utils.get_dataloader", side_effect=fake_dl)
    @patch(
        "ng_model_gym.core.utils.export_utils.load_checkpoint",
        new=lambda *a, **k: MockFeedbackModel(),
    )
    @patch("ng_model_gym.core.utils.export_utils._export_module_to_vgf", new=DEFAULT)
    @patch("ng_model_gym.core.utils.export_utils._check_cuda", new=lambda: None)
    @patch(
        "ng_model_gym.core.utils.export_utils.model_tracer",
        new=lambda model, preprocess: torch.zeros(1, 1),
    )
    def test_fp32_path(
        self, mock_export_module_to_vgf, mock_get_dataloader, mock_update_metadata_file
    ):
        """Test the FP32 export path."""
        params = make_params(self.tmp_path)
        executorch_vgf_export(
            params=params,
            export_type=ExportType.FP32,
            model_path=Path("checkpoint.pth"),
        )

        # Train/eval mode set correctly.
        self.assertEqual(params.model_train_eval_mode, TrainEvalMode.FP32)

        model_key = get_model_key(params.model.name, params.model.version)

        # Metadata file should be updated with constants.
        expected_meta = Path(params.output.export.vgf_output_dir) / (
            f"{model_key}-{ExportType.FP32.name}-metadata.json"
        )
        mock_update_metadata_file.assert_called_once_with(expected_meta, {"foo": "bar"})

        # Dataloader correct arguments passed.
        _, kwargs = mock_get_dataloader.call_args
        self.assertEqual(kwargs["loader_mode"], DataLoaderMode.TEST)
        self.assertTrue(kwargs["trace_mode"])

        # Export module to a VGF file called with correct parameters.
        mock_export_module_to_vgf.assert_called_once()
        export_args, _ = mock_export_module_to_vgf.call_args
        _, module, trace_input, etype, meta_path = export_args
        self.assertIsInstance(module, BaseNGModel)
        self.assertIsInstance(trace_input, torch.Tensor)
        self.assertEqual(etype, ExportType.FP32)

        model_key = get_model_key(params.model.name, params.model.version)

        # Metadata path should match the expected path.
        expected_meta = Path(params.output.export.vgf_output_dir) / (
            f"{model_key}-{ExportType.FP32.name}-metadata.json"
        )
        self.assertEqual(meta_path, expected_meta)

    @patch("ng_model_gym.core.utils.export_utils._check_cuda", new=lambda: None)
    @patch(
        "ng_model_gym.core.utils.export_utils.load_checkpoint",
        new=lambda *a, **k: MockFeedbackModel(),
    )
    @patch("ng_model_gym.core.utils.export_utils.get_dataloader", new=fake_dl)
    @patch(
        "ng_model_gym.core.utils.export_utils._export_module_to_vgf",
        new=lambda *a, **k: None,
    )
    @patch(
        "ng_model_gym.core.utils.export_utils.model_tracer",
        new=lambda model, preprocess: torch.zeros(1, 1),
    )
    def test_metadata_file_is_created(self):
        """Test that metadata file is created with constants when exporting."""
        params = make_params(self.tmp_path)

        # Run with FP32 branch.
        executorch_vgf_export(params, ExportType.FP32, Path("doesnt_matter.pth"))

        model_key = get_model_key(params.model.name, params.model.version)

        # Build expected path.
        meta_path = (
            Path(params.output.export.vgf_output_dir)
            / f"{model_key}-{ExportType.FP32.name}-metadata.json"
        )

        # File must now exist.
        self.assertTrue(
            meta_path.exists(), f"Expected metadata file at {meta_path} to exist"
        )

        # And contain exactly the constants dict.
        data = json.loads(meta_path.read_text(encoding="utf-8"))
        self.assertEqual(data, {"foo": "bar"})

    @patch("ng_model_gym.core.utils.export_utils._check_cuda", new=lambda: None)
    @patch(
        "ng_model_gym.core.utils.export_utils.load_checkpoint",
        new=lambda *a, **k: MockFeedbackModel(),
    )
    def test_inputs_channels_last_for_4d(self):
        """Ensure 4D tensors become channels_last and non-tensors unchanged."""

        # Build nested input with 4D + non-4D tensors and non-tensors.
        tensor_nchw = torch.arange(2 * 3 * 4 * 5, dtype=torch.float32).reshape(
            2, 3, 4, 5
        )
        tensor_4d = torch.randn(1, 1, 2, 2)
        tensor_3d = torch.randn(3, 4, 5)
        non_tensor = {"k": 123, "s": "testing"}

        nested_input = (
            {"img": tensor_nchw, "meta": non_tensor},
            [tensor_4d, tensor_3d, 7],
        )

        def local_dl(
            params, num_workers, prefetch_factor, loader_mode, trace_mode
        ):  # pylint: disable=unused-argument
            yield (nested_input, 0)

        # Make tracer return preprocess input unchanged to observe changes from export_utils
        def passthrough_tracer(
            model, preprocess_trace_input
        ):  # pylint: disable=unused-argument
            return preprocess_trace_input

        # Capture model_forward_input passed into _export_module_to_vgf
        captured = {}

        def capture_export(
            params, model, model_forward_input, export_type, metadata_path
        ):  # pylint: disable=unused-argument
            captured["input"] = model_forward_input

        with patch(
            "ng_model_gym.core.utils.export_utils.get_dataloader", side_effect=local_dl
        ), patch(
            "ng_model_gym.core.utils.export_utils.model_tracer", new=passthrough_tracer
        ), patch(
            "ng_model_gym.core.utils.export_utils._export_module_to_vgf",
            new=capture_export,
        ), patch(
            "ng_model_gym.core.utils.export_utils._update_metadata_file",
            new=lambda *a, **k: None,
        ):
            params = make_params(self.tmp_path)
            executorch_vgf_export(
                params=params,
                export_type=ExportType.FP32,
                model_path=Path("checkpoint.pt"),
            )

        self.assertIn("input", captured, "Export did not reach the VGF step.")
        transformed = captured["input"]

        # Tensor values, dtypes and shapes preserved
        orig_tensors = _flatten(nested_input)
        new_tensors = _flatten(transformed)
        self.assertEqual(len(orig_tensors), len(new_tensors))

        for o, n in zip(orig_tensors, new_tensors):
            self.assertIsInstance(n, torch.Tensor)
            self.assertEqual(o.shape, n.shape)
            self.assertEqual(o.dtype, n.dtype)
            self.assertTrue(
                torch.allclose(o.detach().cpu(), n),
                "Tensor values changed during format move.",
            )

        # 4D tensors must be channels_last
        for t in new_tensors:
            if t.ndim == 4:
                self.assertTrue(
                    (t.is_contiguous(memory_format=torch.channels_last)),
                    "4D tensor was not channels_last.",
                )

        # Non-tensor payload should be unchanged
        self.assertIsInstance(transformed, tuple)
        self.assertEqual(transformed[0]["meta"]["k"], 123)
        self.assertEqual(transformed[0]["meta"]["s"], "testing")


if __name__ == "__main__":
    unittest.main()
